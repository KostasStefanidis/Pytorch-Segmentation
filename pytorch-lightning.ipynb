{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, LearningRateFinder, TQDMProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchsummary import summary\n",
    "import yaml\n",
    "from lib.datasets.cityscapes import CityscapesDataModule\n",
    "from lib.models.base_module import SegmentationModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configuration from config yaml\n"
     ]
    }
   ],
   "source": [
    "# Read YAML file\n",
    "print('Reading configuration from config yaml')\n",
    "\n",
    "with open('config/Cityscapes.yaml', 'r') as config_file:\n",
    "    config: dict = yaml.safe_load(config_file)\n",
    "\n",
    "# TODO: Add default values if a variable is not defined in the config file\n",
    "\n",
    "LOGS_DIR = config.get('logs_dir')\n",
    "model_config: dict = config.get('model_config')\n",
    "dataset_config: dict = config.get('dataset_config')\n",
    "train_config: dict = config.get('train_config')\n",
    "augmentation_config: dict = train_config.get('augmentations')\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET = dataset_config.get('name')\n",
    "NUM_TRAIN_BATCHES = dataset_config.get('num_train_batches', 1.0)\n",
    "NUM_EVAL_BATCHES = dataset_config.get('num_eval_batches', 1.0)\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_TYPE = model_config.get('architecture')\n",
    "MODEL_NAME = model_config.get('name')\n",
    "\n",
    "EPOCHS = train_config.get('epochs') #\n",
    "PRECISION = str(train_config.get('precision')) #\n",
    "DISTRIBUTE_STRATEGY = train_config.get('distribute').get('strategy')\n",
    "DEVICES = train_config.get('distribute').get('devices')\n",
    "USE_EARLY_STOPPING = train_config.get('early_stopping', False)\n",
    "# Stohastic weight averaging parameters\n",
    "SWA = train_config.get('swa')\n",
    "if SWA is not None:\n",
    "    SWA_LRS = SWA.get('lr', 1e-3)\n",
    "    SWA_EPOCH_START = SWA.get('epoch_start', 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = f'saved_models/{MODEL_TYPE}/{MODEL_NAME}'\n",
    "model_checkpoint_callback = ModelCheckpoint(dirpath=LOGS_DIR,\n",
    "                                            filename=model_checkpoint_path,\n",
    "                                            save_weights_only=False,\n",
    "                                            monitor='val_loss',\n",
    "                                            mode='min',\n",
    "                                        #    monitor='MeanIoU',\n",
    "                                        #    mode='max',\n",
    "                                            verbose=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(patience=6,\n",
    "                                        monitor='val_loss',\n",
    "                                        # mode='max',\n",
    "                                        min_delta=1e-6,\n",
    "                                        verbose=True,\n",
    "                                        strict=True,\n",
    "                                        check_finite=True,\n",
    "                                        log_rank_zero_only=True)\n",
    "\n",
    "#profiler = AdvancedProfiler(dirpath=LOGS_DIR, filename=\"perf_logs\")\n",
    "#lr_finder_callback = LearningRateFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [model_checkpoint_callback, ModelSummary(max_depth=3)]\n",
    "#, DeviceStatsMonitor()\n",
    "if SWA is not None:\n",
    "    swa_callback = StochasticWeightAveraging(swa_lrs=SWA_LRS,\n",
    "                                         swa_epoch_start=SWA_EPOCH_START)\n",
    "    callbacks.append(swa_callback)\n",
    "    \n",
    "if USE_EARLY_STOPPING:\n",
    "    callbacks.append(early_stopping_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir=f'{LOGS_DIR}/Tensorboard_logs', name=f'{MODEL_TYPE}/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Augmentations: Compose(    ColorJitter(brightness=(0.7, 1.3), contrast=(0.7, 1.3), saturation=(0.8, 1.2)))\n",
      "Using Augmentations: Compose(\n",
      "      ColorJitter(brightness=(0.7, 1.3), contrast=(0.7, 1.3), saturation=(0.8, 1.2))\n",
      "      RandomRotation(degrees=[-10.0, 10.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)\n",
      ")\n",
      "Using Augmentations: Compose(\n",
      "      ColorJitter(brightness=(0.7, 1.3), contrast=(0.7, 1.3), saturation=(0.8, 1.2))\n",
      "      RandomRotation(degrees=[-10.0, 10.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)\n",
      "      RandomHorizontalFlip(p=0.5)\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "random_paok is not in the list of supported transforms for augmentation. Supported augmentations are: ['color_jitter', 'horizontal_flip', 'random_rotation', 'gaussian_blur']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m SegmentationModule(\n\u001b[1;32m      2\u001b[0m     model_config \u001b[39m=\u001b[39m model_config,\n\u001b[1;32m      3\u001b[0m     train_config\u001b[39m=\u001b[39mtrain_config,\n\u001b[1;32m      4\u001b[0m     logs_dir\u001b[39m=\u001b[39mLOGS_DIR\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m data_module \u001b[39m=\u001b[39m CityscapesDataModule(dataset_config, augmentation_config)\n\u001b[1;32m      9\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m     10\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     devices\u001b[39m=\u001b[39mDEVICES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39m#sync_batchnorm=True,\u001b[39;00m\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m/mnt/Pytorch-Segmentation/lib/datasets/cityscapes.py:177\u001b[0m, in \u001b[0;36mCityscapesDataModule.__init__\u001b[0;34m(self, dataset_config, augmentation_config, transform, target_transform)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39m=\u001b[39m DEFAULT_TARGET_TRANSFORM(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39m=\u001b[39m transform \u001b[39mif\u001b[39;00m transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m DEFAULT_TRANSFORM\n\u001b[0;32m--> 177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentations \u001b[39m=\u001b[39m get_augmentations(augmentation_config)\n",
      "File \u001b[0;32m/mnt/Pytorch-Segmentation/lib/utils/augmentation.py:36\u001b[0m, in \u001b[0;36mget_augmentations\u001b[0;34m(augmentation_config)\u001b[0m\n\u001b[1;32m     33\u001b[0m     augmentation_list\u001b[39m.\u001b[39mappend(GaussianBlur(kernel_size, sigma))\n\u001b[1;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_AUGMENTATION_NOT_SUPPORTED_ERROR(augmentation))\n\u001b[1;32m     38\u001b[0m augmentations \u001b[39m=\u001b[39m Compose(augmentation_list)\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUsing Augmentations: \u001b[39m\u001b[39m{\u001b[39;00maugmentations\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: random_paok is not in the list of supported transforms for augmentation. Supported augmentations are: ['color_jitter', 'horizontal_flip', 'random_rotation', 'gaussian_blur']\n"
     ]
    }
   ],
   "source": [
    "model = SegmentationModule(\n",
    "    model_config = model_config,\n",
    "    train_config=train_config,\n",
    "    logs_dir=LOGS_DIR\n",
    ")\n",
    "\n",
    "data_module = CityscapesDataModule(dataset_config, augmentation_config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=DEVICES,\n",
    "    limit_train_batches=NUM_TRAIN_BATCHES,\n",
    "    limit_val_batches=NUM_EVAL_BATCHES,\n",
    "    max_epochs=EPOCHS,\n",
    "    #precision=PRECISION,\n",
    "    deterministic=False,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=LOGS_DIR,\n",
    "    logger=logger,\n",
    "    #strategy=DISTRIBUTE_STRATEGY\n",
    "    #profiler='simple',\n",
    "    #sync_batchnorm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/mnt/logs/saved_models/DeepLabV3/Full1.ckpt')\n",
    "print(checkpoint.keys())\n",
    "checkpoint['hyper_parameters']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegmentationModule.load_from_checkpoint('/mnt/logs/saved_models/DeepLabV3/Full1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(model, datamodule=data_module, return_predictions=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
