{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, LearningRateFinder, TQDMProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchsummary import summary\n",
    "import yaml\n",
    "from lib.datasets.cityscapes import CityscapesDataModule\n",
    "from lib.models.base_module import SegmentationModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configuration from config yaml\n"
     ]
    }
   ],
   "source": [
    "# Read YAML file\n",
    "print('Reading configuration from config yaml')\n",
    "\n",
    "with open('config/Cityscapes.yaml', 'r') as config_file:\n",
    "    config: dict = yaml.safe_load(config_file)\n",
    "\n",
    "# TODO: Add default values if a variable is not defined in the config file\n",
    "\n",
    "LOGS_DIR = config.get('logs_dir')\n",
    "model_config: dict = config.get('model_config')\n",
    "dataset_config: dict = config.get('dataset_config')\n",
    "train_config: dict = config.get('train_config')\n",
    "augmentation_config: dict = train_config.get('augmentations')\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET = dataset_config.get('name')\n",
    "NUM_TRAIN_BATCHES = dataset_config.get('num_train_batches', 1.0)\n",
    "NUM_EVAL_BATCHES = dataset_config.get('num_eval_batches', 1.0)\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_TYPE = model_config.get('architecture')\n",
    "MODEL_NAME = model_config.get('name')\n",
    "\n",
    "EPOCHS = train_config.get('epochs') #\n",
    "PRECISION = str(train_config.get('precision')) #\n",
    "DISTRIBUTE_STRATEGY = train_config.get('distribute').get('strategy')\n",
    "DEVICES = train_config.get('distribute').get('devices')\n",
    "USE_EARLY_STOPPING = train_config.get('early_stopping', False)\n",
    "# Stohastic weight averaging parameters\n",
    "SWA = train_config.get('swa')\n",
    "if SWA is not None:\n",
    "    SWA_LRS = SWA.get('lr', 1e-3)\n",
    "    SWA_EPOCH_START = SWA.get('epoch_start', 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = f'saved_models/{MODEL_TYPE}/{MODEL_NAME}'\n",
    "model_checkpoint_callback = ModelCheckpoint(dirpath=LOGS_DIR,\n",
    "                                            filename=model_checkpoint_path,\n",
    "                                            save_weights_only=False,\n",
    "                                            monitor='val_loss',\n",
    "                                            mode='min',\n",
    "                                        #    monitor='MeanIoU',\n",
    "                                        #    mode='max',\n",
    "                                            verbose=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(patience=6,\n",
    "                                        monitor='val_loss',\n",
    "                                        # mode='max',\n",
    "                                        min_delta=1e-6,\n",
    "                                        verbose=True,\n",
    "                                        strict=True,\n",
    "                                        check_finite=True,\n",
    "                                        log_rank_zero_only=True)\n",
    "\n",
    "#profiler = AdvancedProfiler(dirpath=LOGS_DIR, filename=\"perf_logs\")\n",
    "#lr_finder_callback = LearningRateFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [model_checkpoint_callback, ModelSummary(max_depth=3)]\n",
    "#, DeviceStatsMonitor()\n",
    "if SWA is not None:\n",
    "    swa_callback = StochasticWeightAveraging(swa_lrs=SWA_LRS,\n",
    "                                         swa_epoch_start=SWA_EPOCH_START)\n",
    "    callbacks.append(swa_callback)\n",
    "    \n",
    "if USE_EARLY_STOPPING:\n",
    "    callbacks.append(early_stopping_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir=f'{LOGS_DIR}/Tensorboard_logs', name=f'{MODEL_TYPE}/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Augmentations: Compose(\n",
      "      ColorJitter(brightness=(0.7, 1.3), contrast=(0.7, 1.3), saturation=(0.8, 1.2))\n",
      "      RandomRotation(degrees=[-10.0, 10.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)\n",
      "      RandomHorizontalFlip(p=0.5)\n",
      "      GaussianBlur(kernel_size=(7, 7), sigma=[0.1, 3.0])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SegmentationModule(\n",
    "    model_config = model_config,\n",
    "    train_config=train_config,\n",
    "    logs_dir=LOGS_DIR\n",
    ")\n",
    "\n",
    "data_module = CityscapesDataModule(dataset_config, augmentation_config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=DEVICES,\n",
    "    limit_train_batches=NUM_TRAIN_BATCHES,\n",
    "    limit_val_batches=NUM_EVAL_BATCHES,\n",
    "    max_epochs=EPOCHS,\n",
    "    #precision=PRECISION,\n",
    "    deterministic=False,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=LOGS_DIR,\n",
    "    logger=logger,\n",
    "    #strategy=DISTRIBUTE_STRATEGY\n",
    "    #profiler='simple',\n",
    "    #sync_batchnorm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kstef/.local/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /mnt/logs exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name               | Type                    | Params\n",
      "----------------------------------------------------------------\n",
      "0  | model              | DeepLabV3               | 11.0 M\n",
      "1  | model.backbone     | IntermediateLayerGetter | 3.0 M \n",
      "2  | model.backbone.0   | Conv2dNormActivation    | 464   \n",
      "3  | model.backbone.1   | InvertedResidual        | 464   \n",
      "4  | model.backbone.2   | InvertedResidual        | 3.4 K \n",
      "5  | model.backbone.3   | InvertedResidual        | 4.4 K \n",
      "6  | model.backbone.4   | InvertedResidual        | 10.3 K\n",
      "7  | model.backbone.5   | InvertedResidual        | 21.0 K\n",
      "8  | model.backbone.6   | InvertedResidual        | 21.0 K\n",
      "9  | model.backbone.7   | InvertedResidual        | 32.1 K\n",
      "10 | model.backbone.8   | InvertedResidual        | 34.8 K\n",
      "11 | model.backbone.9   | InvertedResidual        | 32.0 K\n",
      "12 | model.backbone.10  | InvertedResidual        | 32.0 K\n",
      "13 | model.backbone.11  | InvertedResidual        | 214 K \n",
      "14 | model.backbone.12  | InvertedResidual        | 386 K \n",
      "15 | model.backbone.13  | InvertedResidual        | 429 K \n",
      "16 | model.backbone.14  | InvertedResidual        | 797 K \n",
      "17 | model.backbone.15  | InvertedResidual        | 797 K \n",
      "18 | model.backbone.16  | Conv2dNormActivation    | 155 K \n",
      "19 | model.classifier   | DeepLabHead             | 8.1 M \n",
      "20 | model.classifier.0 | ASPP                    | 7.5 M \n",
      "21 | model.classifier.1 | Conv2d                  | 589 K \n",
      "22 | model.classifier.2 | BatchNorm2d             | 512   \n",
      "23 | model.classifier.3 | ReLU                    | 0     \n",
      "24 | model.classifier.4 | Conv2d                  | 5.1 K \n",
      "25 | loss               | CrossEntropyLoss        | 0     \n",
      "26 | train_mean_iou     | MulticlassJaccardIndex  | 0     \n",
      "27 | val_mean_iou       | MulticlassJaccardIndex  | 0     \n",
      "----------------------------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "44.101    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 0: 100%|█████████▉| 495/496 [09:11<00:01,  1.11s/it, v_num=2]        Adjusting learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 0: 100%|██████████| 496/496 [10:00<00:00,  1.21s/it, v_num=2, val_loss=0.866, val_Mean_IoU=0.290, train_loss=0.503, train_Mean_IoU=0.357]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 496: 'val_loss' reached 0.86642 (best 0.86642), saving model to '/mnt/logs/saved_models/deeplabv3/deeplabv3-mobilenet_v3_large-1-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██        | 104/496 [02:06<07:55,  1.21s/it, v_num=2, val_loss=0.866, val_Mean_IoU=0.290, train_loss=0.503, train_Mean_IoU=0.357]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kstef/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/mnt/logs/saved_models/DeepLabV3/Full1.ckpt')\n",
    "print(checkpoint.keys())\n",
    "checkpoint['hyper_parameters']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegmentationModule.load_from_checkpoint('/mnt/logs/saved_models/DeepLabV3/Full1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(model, datamodule=data_module, return_predictions=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
